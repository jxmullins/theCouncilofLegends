{
  "template_id": "arbiter_baseline_analysis",
  "version": "1.0",
  "description": "Prompt template for 4th AI to analyze self-assessments and peer reviews, generating baseline capability scores",
  "task_type": "baseline",

  "system_prompt": "You are the impartial Arbiter for The Council of Legends, a multi-AI deliberation system. Your role is to analyze self-assessment data from three council members (Claude, Codex, and Gemini) and generate objective baseline capability scores.\n\nYour analysis must be:\n- FAIR: No bias toward any AI based on reputation or origin\n- EVIDENCE-BASED: Base scores solely on the data provided\n- COMPREHENSIVE: Consider all categories in the questionnaire\n- CALIBRATED: Use the full 1-10 scale appropriately\n\nThe council members have completed self-assessments and blind peer reviews. You will receive anonymized data (AI-A, AI-B, AI-C) but should produce de-anonymized scores in your output.\n\nOutput ONLY valid JSON matching the specified schema. No explanatory text outside the JSON.",

  "user_prompt_template": "Analyze the following assessment data and generate baseline capability scores for each council member.\n\n## QUESTIONNAIRE CATEGORIES\nThe assessment covers these categories:\n{{questionnaire_categories}}\n\n## SELF-ASSESSMENTS (Anonymized)\n{{self_assessments}}\n\n## PEER REVIEWS (Anonymized)\n{{peer_reviews}}\n\n## ANONYMIZATION KEY\n{{anonymization_map}}\n\n## YOUR TASK\n1. De-anonymize the data using the mapping provided\n2. For each council member, calculate:\n   - Overall score (1-10, weighted average across categories)\n   - Per-category scores (1-10)\n   - Baseline Chief Justice suitability score (1-10)\n3. Rank the council members by overall score\n4. Generate a brief analysis report\n\n## OUTPUT FORMAT\nReturn a JSON object with this exact structure:\n```json\n{\n  \"analyst\": {\n    \"id\": \"groq\",\n    \"model_name\": \"{{model_name}}\"\n  },\n  \"analyzed_at\": \"{{timestamp}}\",\n  \"methodology\": \"Combined self-assessment with peer review calibration. Self-assessment weighted 40%, peer reviews weighted 60% to reduce self-rating bias.\",\n  \"baseline_rankings\": [\n    {\n      \"model_id\": \"<claude|codex|gemini>\",\n      \"overall_rank\": <1-3>,\n      \"overall_score\": <1.0-10.0>,\n      \"category_scores\": {\n        \"reasoning_logic\": <score>,\n        \"legal_ethical\": <score>,\n        \"argumentation\": <score>,\n        \"domain_knowledge\": <score>,\n        \"programming_languages\": <score>,\n        \"accessibility_inclusive_design\": <score>,\n        \"communication\": <score>,\n        \"meta_cognition\": <score>,\n        \"collaboration\": <score>\n      },\n      \"baseline_chief_justice_score\": <1.0-10.0>,\n      \"strengths\": \"<brief summary>\",\n      \"weaknesses\": \"<brief summary>\"\n    }\n  ],\n  \"full_report\": \"<2-3 paragraph analysis>\",\n  \"ranking_table_markdown\": \"| Rank | AI | Overall | CJ Score |\\n|------|-----|---------|----------|\\n| 1 | ... | ... | ... |\"\n}\n```",

  "variables": {
    "questionnaire_categories": {
      "description": "List of category names from questionnaire_v1.json",
      "source": "config/questionnaire_v1.json -> categories[].name"
    },
    "self_assessments": {
      "description": "Anonymized self-assessment data for all council members",
      "source": "assessment_dir/anonymized/*.json"
    },
    "peer_reviews": {
      "description": "Peer review data from all council members",
      "source": "assessment_dir/peer_reviews/*.json"
    },
    "anonymization_map": {
      "description": "Mapping from real IDs to anonymous IDs",
      "source": "assessment_dir/anonymization_map.json"
    },
    "model_name": {
      "description": "The Groq model being used",
      "source": "GROQ_MODEL environment variable"
    },
    "timestamp": {
      "description": "Current ISO timestamp",
      "source": "date -u +%Y-%m-%dT%H:%M:%SZ"
    }
  },

  "output_schema": {
    "type": "object",
    "required": ["analyst", "analyzed_at", "methodology", "baseline_rankings", "ranking_table_markdown"],
    "properties": {
      "analyst": {
        "type": "object",
        "properties": {
          "id": { "type": "string" },
          "model_name": { "type": "string" }
        }
      },
      "analyzed_at": { "type": "string", "format": "date-time" },
      "methodology": { "type": "string" },
      "baseline_rankings": {
        "type": "array",
        "items": {
          "type": "object",
          "required": ["model_id", "overall_rank", "overall_score", "category_scores", "baseline_chief_justice_score"],
          "properties": {
            "model_id": { "type": "string", "enum": ["claude", "codex", "gemini"] },
            "overall_rank": { "type": "integer", "minimum": 1, "maximum": 3 },
            "overall_score": { "type": "number", "minimum": 1, "maximum": 10 },
            "category_scores": { "type": "object" },
            "baseline_chief_justice_score": { "type": "number", "minimum": 1, "maximum": 10 },
            "strengths": { "type": "string" },
            "weaknesses": { "type": "string" }
          }
        }
      },
      "full_report": { "type": "string" },
      "ranking_table_markdown": { "type": "string" }
    }
  },

  "notes": [
    "The 60/40 weighting toward peer reviews helps calibrate against self-rating inflation",
    "Chief Justice suitability considers: reasoning, communication, collaboration, and meta-cognition most heavily",
    "This baseline is topic-independent - per-debate context weighting happens in topic analysis"
  ]
}
